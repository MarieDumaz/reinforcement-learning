{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTS\n",
    "\n",
    "import gym\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create environment\n",
    "env = gym.make(\"Taxi-v3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize variables\n",
    "num_states = env.observation_space.n # Number of states\n",
    "num_actions = env.action_space.n # Number of actions\n",
    "max_iter = 1000 # Number of iterations\n",
    "\n",
    "# Value Function vector\n",
    "V = np.zeros([num_states])\n",
    "# Policy vector\n",
    "P = np.random.choice(num_actions, size=num_states)\n",
    "\n",
    "gamma = 0.9 # Discount parameter\n",
    "delta_threshold = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Policy Iteration Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of iterations: 16\n",
      "Value function size: 500\n",
      "\n",
      "Value Function: \n",
      "\n",
      "[ 89.47368421  32.82015931  55.26468333  37.57795479   8.43267451\n",
      "  32.82015931   8.43267363  15.28487587  32.82015931  18.09430652\n",
      "  55.26468333  21.21589614  12.75638828  18.09430652  12.7563874\n",
      "  37.57795479 100.52631579  37.57795479  62.516315    42.86439421\n",
      "  79.52631579  28.53814338  48.738215    32.82015931  10.48074946\n",
      "  37.57795479  10.48074866  18.09430652  28.53814338  15.28487587\n",
      "  48.738215    18.09430652  15.28487587  21.21589614  15.28487508\n",
      "  42.86439421  89.47368421  42.86439421  55.2646835   48.73821579\n",
      "  42.86439421  12.75638828  24.68432833  15.28487587  24.68432904\n",
      "  70.57368421  24.68432833  37.57795479  24.68432904  12.75638828\n",
      "  42.8643935   15.28487587  18.09430652  24.68432904  18.09430581\n",
      "  48.73821579  48.73821579  79.52631579  48.73821515  55.26468421\n",
      "  37.57795479  10.48074946  21.2158955   12.75638828  28.53814338\n",
      "  79.52631579  28.53814274  42.86439421  21.21589614  10.48074946\n",
      "  37.57795415  12.75638828  21.21589614  28.53814338  21.2158955\n",
      "  55.26468421  42.86439421  89.47368421  42.86439363  62.51631579\n",
      "  32.82015931   8.43267451  18.09430595  10.48074946  32.82015931\n",
      "  89.47368421  32.82015873  48.73821579  18.09430652   8.43267451\n",
      "  32.82015873  10.48074946  18.09430652  24.68432904  18.09430595\n",
      "  48.73821579  37.57795479 100.52631579  37.57795427  55.26468421\n",
      "  79.52631579  28.53814338  48.738215    32.82015931  10.48074946\n",
      "  37.57795479  10.48074866  18.09430652  37.57795479  21.21589614\n",
      "  62.516315    24.68432904  15.28487587  21.21589614  15.28487508\n",
      "  42.86439421  89.47368421  42.86439421  70.5736835   48.73821579\n",
      "  70.57368421  24.68432904  42.8643935   28.53814338  12.75638828\n",
      "  42.86439421  12.75638757  21.21589614  32.82015931  18.09430652\n",
      "  55.2646835   21.21589614  18.09430652  24.68432904  18.09430581\n",
      "  48.73821579  79.52631579  48.73821579  62.51631515  55.26468421\n",
      "  48.73821579  15.28487587  28.53814274  18.09430652  21.21589614\n",
      "  62.51631579  21.2158955   32.82015931  28.53814338  15.28487587\n",
      "  48.73821515  18.09430652  21.21589614  28.53814338  21.2158955\n",
      "  55.26468421  55.26468421  70.57368421  55.26468363  62.51631579\n",
      "  42.86439421  12.75638828  24.68432846  15.28487587  24.68432904\n",
      "  70.57368421  24.68432846  37.57795479  24.68432904  12.75638828\n",
      "  42.86439363  15.28487587  24.68432904  32.82015931  24.68432846\n",
      "  62.51631579  48.73821579  79.52631579  48.73821527  70.57368421\n",
      "  37.57795479  10.48074946  21.21589562  12.75638828  28.53814338\n",
      "  79.52631579  28.53814286  42.86439421  21.21589614  10.48074946\n",
      "  37.57795427  12.75638828  21.21589614  28.53814338  21.21589562\n",
      "  55.26468421  42.86439421  89.47368421  42.86439374  62.51631579\n",
      "  70.57368421  24.68432904  42.8643935   28.53814338  12.75638828\n",
      "  42.86439421  12.75638757  21.21589614  42.86439421  24.68432904\n",
      "  70.5736835   28.53814338  18.09430652  24.68432904  18.09430581\n",
      "  48.73821579  79.52631579  48.73821579  79.52631515  55.26468421\n",
      "  62.51631579  21.21589614  37.57795415  24.68432904  15.28487587\n",
      "  48.73821579  15.28487523  24.68432904  37.57795479  21.21589614\n",
      "  62.51631515  24.68432904  21.21589614  28.53814338  21.2158955\n",
      "  55.26468421  70.57368421  55.26468421  70.57368363  62.51631579\n",
      "  55.26468421  18.09430652  32.82015873  21.21589614  18.09430652\n",
      "  55.26468421  18.09430595  28.53814338  32.82015931  18.09430652\n",
      "  55.26468363  21.21589614  24.68432904  32.82015931  24.68432846\n",
      "  62.51631579  62.51631579  62.51631579  62.51631527  70.57368421\n",
      "  48.73821579  15.28487587  28.53814286  18.09430652  21.21589614\n",
      "  62.51631579  21.21589562  32.82015931  28.53814338  15.28487587\n",
      "  48.73821527  18.09430652  28.53814338  37.57795479  28.53814286\n",
      "  70.57368421  55.26468421  70.57368421  55.26468374  79.52631579\n",
      "  42.86439421  12.75638828  24.68432857  15.28487587  24.68432904\n",
      "  70.57368421  24.68432857  37.57795479  24.68432904  12.75638828\n",
      "  42.86439374  15.28487587  24.68432904  32.82015931  24.68432857\n",
      "  62.51631579  48.73821579  79.52631579  48.73821537  70.57368421\n",
      "  62.51631579  21.21589614  37.57795415  24.68432904  10.48074946\n",
      "  37.57795479  10.48074881  18.09430652  48.73821579  28.53814338\n",
      "  79.52631515  32.82015931  15.28487587  21.21589614  15.28487523\n",
      "  42.86439421  70.57368421  42.86439421  89.47368363  48.73821579\n",
      "  55.26468421  18.09430652  32.82015873  21.21589614  12.75638828\n",
      "  42.86439421  12.75638771  21.21589614  32.82015931  18.09430652\n",
      "  55.26468363  21.21589614  18.09430652  24.68432904  18.09430595\n",
      "  48.73821579  62.51631579  48.73821579  62.51631527  55.26468421\n",
      "  48.73821579  15.28487587  28.53814286  18.09430652  15.28487587\n",
      "  48.73821579  15.28487535  24.68432904  28.53814338  15.28487587\n",
      "  48.73821527  18.09430652  21.21589614  28.53814338  21.21589562\n",
      "  55.26468421  55.26468421  55.26468421  55.26468374  62.51631579\n",
      "  42.86439421  12.75638828  24.68432857  15.28487587  18.09430652\n",
      "  55.26468421  18.09430606  28.53814338  24.68432904  12.75638828\n",
      "  42.86439374  15.28487587  32.82015931  42.86439421  32.82015884\n",
      "  79.52631579  48.73821579  62.51631579  48.73821537  89.47368421\n",
      "  37.57795479  10.48074946  21.21589572  12.75638828  21.21589614\n",
      "  62.51631579  21.21589572  32.82015931  21.21589614  10.48074946\n",
      "  37.57795437  12.75638828  28.53814338  37.57795479  28.53814296\n",
      "  70.57368421  42.86439421  70.57368421  42.86439383  79.52631579\n",
      "  55.26468421  18.09430652  32.82015873  21.21589614   8.43267451\n",
      "  32.82015931   8.43267393  15.28487587  55.26468421  32.82015931\n",
      "  89.47368363  37.57795479  12.75638828  18.09430652  12.75638771\n",
      "  37.57795479  62.51631579  37.57795479 100.52631527  42.86439421\n",
      "  48.73821579  15.28487587  28.53814286  18.09430652  10.48074946\n",
      "  37.57795479  10.48074894  18.09430652  28.53814338  15.28487587\n",
      "  48.73821527  18.09430652  15.28487587  21.21589614  15.28487535\n",
      "  42.86439421  55.26468421  42.86439421  55.26468374  48.73821579\n",
      "  42.86439421  12.75638828  24.68432857  15.28487587  12.75638828\n",
      "  42.86439421  12.75638782  21.21589614  24.68432904  12.75638828\n",
      "  42.86439374  15.28487587  18.09430652  24.68432904  18.09430606\n",
      "  48.73821579  48.73821579  48.73821579  48.73821537  55.26468421\n",
      "  37.57795479  10.48074946  21.21589572  12.75638828  15.28487587\n",
      "  48.73821579  15.28487545  24.68432904  21.21589614  10.48074946\n",
      "  37.57795437  12.75638828  37.57795479  48.73821579  37.57795437\n",
      "  89.47368421  42.86439421  55.26468421  42.86439383 100.52631579\n",
      "  32.82015931   8.43267451  18.09430614  10.48074946  18.09430652\n",
      "  55.26468421  18.09430614  28.53814338  18.09430652   8.43267451\n",
      "  32.82015893  10.48074946  32.82015931  42.86439421  32.82015893\n",
      "  79.52631579  37.57795479  62.51631579  37.57795445  89.47368421]\n"
     ]
    }
   ],
   "source": [
    "# Algorithm stops when policy is stable\n",
    "policy_stable = False\n",
    "m = 0 # Counter\n",
    "\n",
    "env.reset()\n",
    "\n",
    "while (not policy_stable) and (m<max_iter):\n",
    "    # Main loop to reach optimum\n",
    "    \n",
    "    # Policy Evaluation: find value function\n",
    "    stop = False\n",
    "    while not stop:\n",
    "        # While optimum value function is not found\n",
    "        \n",
    "        value_fn = 0\n",
    "        \n",
    "        for state in range(num_states):\n",
    "            # For each state\n",
    "            \n",
    "            # Previous value function\n",
    "            value_fn_prev = V[state]\n",
    "            # Go to current state\n",
    "            env.env.s = state\n",
    "            # Take action depending on policy\n",
    "            observation, reward, done, info = env.step(P[state])\n",
    "            # Update value function\n",
    "            V[state] = reward + gamma * V[observation]\n",
    "            # Rate of improvement\n",
    "            value_fn = max(value_fn, np.abs(value_fn_prev - V[state]))\n",
    "            \n",
    "        # If value function improvement is less than delta, optimum reached\n",
    "        if value_fn < delta_threshold:\n",
    "            stop = True\n",
    "    \n",
    "    # Policy Iteration: Find improved policy\n",
    "    policy_stable = True\n",
    "    for state in range (0, num_states):\n",
    "        # For each state\n",
    "        \n",
    "        # Previous action for that state\n",
    "        prev_action = P[state]\n",
    "        \n",
    "        # Find best action for that state\n",
    "        # Initalize variables for comparison\n",
    "        best_action = None\n",
    "        best_value = float('-inf')\n",
    "        \n",
    "        for action in range(num_actions):\n",
    "            # For each action possible in this state\n",
    "            # Go to current state\n",
    "            env.env.s = state\n",
    "            # Take action\n",
    "            observation, reward, done, info = env.step(action)\n",
    "            # Find corresponding value function\n",
    "            v = reward + gamma * V[observation]\n",
    "            # If value function is higher than previous maximum, it becomes the best action\n",
    "            if v > best_value:\n",
    "                best_value = v\n",
    "                best_action = action\n",
    "        \n",
    "        # Store best action\n",
    "        P[state] = best_action \n",
    "        # Update policy_stable if needed\n",
    "        if prev_action != best_action:\n",
    "            policy_stable = False\n",
    "    \n",
    "    m = m+1\n",
    "\n",
    "print(f'Total number of iterations: {m}')\n",
    "print(f'Value function size: {V.size}\\n')\n",
    "print('Value Function: \\n')\n",
    "print(V)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How well our optimal policy works?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intial state (random)\n",
      "+---------+\n",
      "|\u001b[34;1mR\u001b[0m: | : :G|\n",
      "| : | : :\u001b[43m \u001b[0m|\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "\n",
      "Steps taken by policy\n",
      "+---------+\n",
      "|\u001b[34;1mR\u001b[0m: | : :G|\n",
      "| : | : : |\n",
      "| : : : :\u001b[43m \u001b[0m|\n",
      "| | : | : |\n",
      "|Y| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (South)\n",
      "+---------+\n",
      "|\u001b[34;1mR\u001b[0m: | : :G|\n",
      "| : | : : |\n",
      "| : : :\u001b[43m \u001b[0m: |\n",
      "| | : | : |\n",
      "|Y| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (West)\n",
      "+---------+\n",
      "|\u001b[34;1mR\u001b[0m: | : :G|\n",
      "| : | : : |\n",
      "| : :\u001b[43m \u001b[0m: : |\n",
      "| | : | : |\n",
      "|Y| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (West)\n",
      "+---------+\n",
      "|\u001b[34;1mR\u001b[0m: | : :G|\n",
      "| : | : : |\n",
      "| :\u001b[43m \u001b[0m: : : |\n",
      "| | : | : |\n",
      "|Y| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (West)\n",
      "+---------+\n",
      "|\u001b[34;1mR\u001b[0m: | : :G|\n",
      "| :\u001b[43m \u001b[0m| : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (North)\n",
      "+---------+\n",
      "|\u001b[34;1mR\u001b[0m:\u001b[43m \u001b[0m| : :G|\n",
      "| : | : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (North)\n",
      "+---------+\n",
      "|\u001b[34;1m\u001b[43mR\u001b[0m\u001b[0m: | : :G|\n",
      "| : | : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (West)\n",
      "+---------+\n",
      "|\u001b[42mR\u001b[0m: | : :G|\n",
      "| : | : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (Pickup)\n",
      "+---------+\n",
      "|R: | : :G|\n",
      "|\u001b[42m_\u001b[0m: | : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (South)\n",
      "+---------+\n",
      "|R: | : :G|\n",
      "| : | : : |\n",
      "|\u001b[42m_\u001b[0m: : : : |\n",
      "| | : | : |\n",
      "|Y| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (South)\n",
      "+---------+\n",
      "|R: | : :G|\n",
      "| : | : : |\n",
      "| :\u001b[42m_\u001b[0m: : : |\n",
      "| | : | : |\n",
      "|Y| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (East)\n",
      "+---------+\n",
      "|R: | : :G|\n",
      "| : | : : |\n",
      "| : :\u001b[42m_\u001b[0m: : |\n",
      "| | : | : |\n",
      "|Y| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (East)\n",
      "+---------+\n",
      "|R: | : :G|\n",
      "| : | : : |\n",
      "| : : :\u001b[42m_\u001b[0m: |\n",
      "| | : | : |\n",
      "|Y| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (East)\n",
      "+---------+\n",
      "|R: | : :G|\n",
      "| : | : : |\n",
      "| : : : : |\n",
      "| | : |\u001b[42m_\u001b[0m: |\n",
      "|Y| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (South)\n",
      "+---------+\n",
      "|R: | : :G|\n",
      "| : | : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |\u001b[35m\u001b[42mB\u001b[0m\u001b[0m: |\n",
      "+---------+\n",
      "  (South)\n",
      "+---------+\n",
      "|R: | : :G|\n",
      "| : | : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |\u001b[35m\u001b[34;1m\u001b[43mB\u001b[0m\u001b[0m\u001b[0m: |\n",
      "+---------+\n",
      "  (Dropoff)\n"
     ]
    }
   ],
   "source": [
    "observation = env.reset()\n",
    "print('Intial state (random)')\n",
    "env.render()\n",
    "print('Steps taken by policy')\n",
    "done = False\n",
    "while not done:\n",
    "    observation, reward, done, info = env.step(P[observation])\n",
    "    env.render()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the taxi did not make any mistake, like bumping to a wall, or trying to pickup and dropoff customers at a wrong place. This shows that our policy is optimal."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
